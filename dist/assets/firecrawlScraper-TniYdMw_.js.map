{"version":3,"mappings":";wCAKA,MAAMA,EAAoB,sCACpBC,EAAoB,sCAG1B,IAAIC,EAAkB,KACtB,eAAeC,GAAqB,CAClC,OAAKD,IAEHA,GADuB,YAAM,OAAO,qBAAqB,OAAAE,KAAA,4BACxB,qBAE5BF,CACT,CAOO,eAAeG,EAAoBC,EAAK,CAC7C,GAAI,CACF,QAAQ,IAAI,qCAAqC,EAEjD,MAAMC,EAAW,MAAM,MAAMN,EAAmB,CAC9C,OAAQ,OACR,QAAS,CACP,eAAgB,mBAChB,cAAiB,UAAUD,CAAiB,EACpD,EACM,KAAM,KAAK,UAAU,CACnB,IAAKM,EACL,YAAa,CACX,gBAAiB,EAC3B,EACQ,QAAS,CAAC,OAAQ,UAAU,CACpC,CAAO,CACP,CAAK,EAED,GAAI,CAACC,EAAS,GAAI,CAChB,MAAMC,EAAY,MAAMD,EAAS,KAAI,EAAG,MAAM,KAAO,CAAE,MAAO,eAAe,EAAG,EAChF,MAAM,IAAI,MAAMC,EAAU,OAAS,wBAAwBD,EAAS,MAAM,EAAE,CAC9E,CAEA,MAAME,EAAS,MAAMF,EAAS,KAAI,EAElC,GAAI,CAACE,EAAO,SAAW,CAACA,EAAO,KAC7B,MAAM,IAAI,MAAM,4BAA4B,EAG9C,MAAMC,EAAOD,EAAO,KAAK,MAAQA,EAAO,KAAK,UAAY,GAEzD,GAAI,CAACC,GAAQA,EAAK,OAAS,IACzB,MAAM,IAAI,MAAM,yCAAyC,EAK3D,MAAMC,GADU,MAAMR,EAAkB,GACXO,EAAMJ,CAAG,EAEtC,GAAI,CAACK,GAAgB,CAACA,EAAa,MACjC,MAAM,IAAI,MAAM,wDAAwD,EAG1E,eAAQ,IAAI,gCAAgC,EACrCA,CAET,OAASC,EAAO,CACd,cAAQ,IAAI,gCAAiCA,EAAM,OAAO,EACpDA,CACR,CACF","names":["FIRECRAWL_API_KEY","FIRECRAWL_API_URL","extractFromHTML","getExtractFunction","n","scrapeWithFirecrawl","url","response","errorData","result","html","propertyData","error"],"ignoreList":[],"sources":["../../src/lib/scrapers/firecrawlScraper.js"],"sourcesContent":["/**\n * Firecrawl scraper for property data extraction\n * Used as a backup when primary scraping methods fail\n */\n\nconst FIRECRAWL_API_KEY = 'fc-226de18402264e69afae0e914ffb728d';\nconst FIRECRAWL_API_URL = 'https://api.firecrawl.dev/v0/scrape';\n\n// Dynamic import to avoid circular dependencies\nlet extractFromHTML = null;\nasync function getExtractFunction() {\n  if (!extractFromHTML) {\n    const browserScraper = await import('./browserScraper.js');\n    extractFromHTML = browserScraper.extractPropertyData;\n  }\n  return extractFromHTML;\n}\n\n/**\n * Scrape property data using Firecrawl API\n * @param {string} url - Property URL\n * @returns {Promise<Object>} Property data\n */\nexport async function scrapeWithFirecrawl(url) {\n  try {\n    console.log('ðŸ”„ Attempting Firecrawl scraping...');\n    \n    const response = await fetch(FIRECRAWL_API_URL, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${FIRECRAWL_API_KEY}`\n      },\n      body: JSON.stringify({\n        url: url,\n        pageOptions: {\n          onlyMainContent: false\n        },\n        formats: ['html', 'markdown']\n      })\n    });\n\n    if (!response.ok) {\n      const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));\n      throw new Error(errorData.error || `Firecrawl API error: ${response.status}`);\n    }\n\n    const result = await response.json();\n    \n    if (!result.success || !result.data) {\n      throw new Error('Firecrawl returned no data');\n    }\n\n    const html = result.data.html || result.data.markdown || '';\n    \n    if (!html || html.length < 100) {\n      throw new Error('Firecrawl returned insufficient content');\n    }\n\n    // Extract property data from HTML using the same extraction logic\n    const extract = await getExtractFunction();\n    const propertyData = extract(html, url);\n    \n    if (!propertyData || !propertyData.title) {\n      throw new Error('Could not extract property data from Firecrawl content');\n    }\n\n    console.log('âœ… Firecrawl scraping succeeded');\n    return propertyData;\n\n  } catch (error) {\n    console.log('âš ï¸ Firecrawl scraping failed:', error.message);\n    throw error;\n  }\n}\n\n\n"],"file":"firecrawlScraper-TniYdMw_.js"}